==+== Computer Architecture Paper Review Form
==-== DO NOT CHANGE LINES THAT START WITH "==+==" UNLESS DIRECTED!
==-== For further guidance, or to upload this file when you are done, go to:
==-== https://safari.ethz.ch/review/architecture21/offline

==+== =====================================================================
==+== Begin Review
==+== Reviewer: Guillaume Thivolet <gthivolet@student.ethz.ch>

==+== Paper Number

45

==+== Review Readiness
==-== Enter "Ready" if the review is ready for others to see:

()

==+== A. Overall merit
==-== Choices:
==-==    1. Reject
==-==    2. Weak reject
==-==    3. Weak accept
==-==    4. Accept
==-==    5. Strong accept
==-== Enter the number of your choice:

5

==+== B. Reviewer expertise
==-== Choices:
==-==    1. No familiarity
==-==    2. Some familiarity
==-==    3. Knowledgeable
==-==    4. Expert
==-== Enter the number of your choice:

2

==+== C. Paper summary

The main memory is nowadays shared by multiple cores and the physical memory is split across multiple memory controllers (MC) that all should service the applications loads and stores. The three main goals in designing memory controller's algorithms to service requests are (1) provide consistent performances regardless of workload (2) maximize instruction throughput and (3) minimize synchronization overhead across MCs.

ATLAS can be summarized in the following way. It divides the time into a quantum that is itself split into long quanta.  It introduces the concept of least-attained services (LAS). Every MC is responsible to compute its local LAS for each thread, which is how many times it served a memory request for a thread (higher ranked means less memory requests serviced for this thread). At the end of each quanta, every MC reports to a meta-controller the LAS for each thread. The meta-controller weights sums them and merges the previous ranking computed by the last quanta during quantum. The final ranking for threads that it sends back to the MCs for the next quantum. When choosing which request to handle, ATLAS follows a policy of least-attained thread first, and then uses regular FR-FCFS. This allow for coordination across MCs that take into account the long-term memory intensity of each thread rather than a finer granularity. Additionally it services first the requests that have been outstanding for too long to prevent starvation.

Over a long period, ATLAS increases the computing units throughput by minimizing the amount of time spent stalling for memory requests. Compared to state of the art PAR-BS, FR-FCFS, FCFS (in decreasing performance order), ATLAS instruction throughput is always higher for any workload and the improvement should be even more noticeable as the number of MCs increase.

==+== D. Comments for author

Long batch durations are a bit counterintuitive as finer-grain approaches could seem more versatile to reduce memory episodes. ATLAS chose to have a different perspective, and this in fact is maximizing the long-term as it has been demonstrated on the benchmarks. While I was reading, I came across several points: how to determine best-performing values for T, alpha, and the number of cycles for quantum and quanta, which have all been answered later on.

Overall the paper goes straight to the point and does not loose the reader or overflows him with insignificant detail. 

On the minus side, Figure 7. could plot the increase in atlas speedup for 1-MC, 2-MC 4-MC 8-MC and 16-MC (compared to ATLAS itself for less MCs)

Additional comment:
- Figure 10)b) color ordering is hard to read

# Strength

- Simplicity of the ATLAS in general
- Performance gain compared to PAR-BS (best in class)
- Scalability
- T, alpha, and quantum periods have been tested for a vast range of values
- evaluation of uncoordinated atlas for thread ranking

# Weaknesses

- Empirical determination of thread weight by the OS? (even though mentioned in 7.6)
- Alpha close to 1 could lead to attacks by certain threads (slowing the instruction throughput) as it is unfair to memory demanding threads

==+== E. Comments for PC
==-== Hidden from authors.

==+== Scratchpad (for unsaved private notes)

multiple memorycontrollers to control access to main memory
with coordination accross controllers

improves system thoruhput

least attained service 

multiple memory controllers are used to access a larer physical memory

thread ranking is computed at the beginning of everyy bach of requests (apporx. every 2000 cycles

per thread information within each controller need to be broadcasted to al controllers OR  global  meta controller needs to gather info, compute ranking and broadcast it to all controllers


ATLAS
Lest attained service base thread ranking o maximize system throughput
long time quantum to provide scalaility

execution time is divided into qunta

controllers coordinate to determinea consisten ranking of threads

threads that have attained the least service from memory are ranked highest

every controller uses this ranking to prioritize higher ranked threeads' requests

->scalabilitybc of long quanta ->ensure that information exhcnage is scarse
->starvation freedom by using thresholding (forrcesthe servicing of a request that has been outstanding for too long)

when controllers are aware of each others' state, they can take coordinated actions that can improve system performance

pareto distribution: P(Job > x) = kx^_-\alpha 

MECHANISMS
a thread alternatates betwen
1)memroy episode where the thread is wating for at least one mem. req
2) compute (o mem req)

prioritize thread whose mem episode will end soonest

attained service -> total amount of mem service that a mem episode has received since it started

quantum is a longer period divided into quanta. this is to ensure equity between threads as one could have lots of mem req but then nothing for a long period, whereas thread A could be lots of short mem req pulses.. 

coordination ath the beginning of a quantum for coordination across threads

two majros benefits:
maximizes system thoughput within a quantum by minimizing the time spent in memory episodes

ATLAS has thresholding for non starvation guarantee
addition of thread weights as well

no previous memroy scheduling algortihm tries to prioritize threads by taking into account their long-term memory intensity

+ long batch duration

---- empriical determintion of T, alpha, thread weight

each memroy controller as a local AS value for each thread

each thread's local AS value is sent to the meta controller and then reset to zero

meta controller keeps he totalAS value for each thread and updates it

EVALUATION
memroy intensive and memorynon intensive

PAR-BS assumes to have constant global knowledge which is highly unrealistic BUT ... provides an upper bound on whats achivable 

higher instruction throughput 10.8% comapred to PAR-BS and 7.5% to the idealized PAR-BS. perfomance increase constant accros all workloads

STFM poor results because MC are not coordinated, so the threa slowdown value is innacurate

Efect of memory intensity n thw rokload
-> atlas performs well when the workload is heteregonous

if workload consists of all memory intensve or all memoy non intensive threads then ATLAS performance s less pronounces bc 


+++ uncordinated atlas evaluation for thread rankng

Figure 10)b) color ordering is hard to read

value of a can lead to attacks denying access to other theads

atlas is ufair to memory intensive threads that are likely to be less affected by additional delay than non intensive ones
==+== End Review
