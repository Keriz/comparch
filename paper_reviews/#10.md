==+== Computer Architecture Paper Review Form
==-== DO NOT CHANGE LINES THAT START WITH "==+==" UNLESS DIRECTED!
==-== For further guidance, or to upload this file when you are done, go to:
==-== https://safari.ethz.ch/review/architecture21/offline

==+== =====================================================================
==+== Begin Review
==+== Reviewer: Guillaume Thivolet <gthivolet@student.ethz.ch>

==+== Paper Number

10

==+== Review Readiness
==-== Enter "Ready" if the review is ready for others to see:

Ready

==+== A. Overall merit
==-== Choices:
==-==    1. Reject
==-==    2. Weak reject
==-==    3. Weak accept
==-==    4. Accept
==-==    5. Strong accept
==-== Enter the number of your choice:

4

==+== B. Reviewer expertise
==-== Choices:
==-==    1. No familiarity
==-==    2. Some familiarity
==-==    3. Knowledgeable
==-==    4. Expert
==-== Enter the number of your choice:

1

==+== C. Paper summary

The paper present  two new methods for hash codings, which are evaluated according to three factors: the hash size area size, the access time and the allowable fraction of errors. In a more classical hash function, there are no possibilities of getting an error. The methods permit for some error rate in the hashing with false positives, but no false negatives. The gain is a greatly diminished impact on the storage space which allows for bigger sets to have their hash area realistically storable. An example is shown for an automatic hyphenation of a large dictionary, that the author compared to traditional methods, saving 88.5% of space with a 1/64 accepted error rate.

==+== D. Comments for author

# Strengths

+ Normalized space/time tradeoff measurement (removed set size dependency for analysis)
+ Thorough analysis of the three methods
+ Novelty of the presented method

# Weaknesses

+ The analysis assumes a bit-by-bit access, which is never the case
+ Notations are not consistent / well chosen across the paper (b,c,h,\phi,d,N,x)
+ The method 1 seems to serve only as a benchmarking to prove the second method's efficiency.
+ Missing a conclusion

The paper is well redacted and easy to follow. The method presented drastically reduces the necessary has storage size, which could be a bottleneck in the future. The analysis of the performance improvement assumed a precise pattern for hashing match verification (ie. bit-by-bit, sequential verification), which is a huge hypothesis shortcut. Nevertheless, the method and the analysis presented are enough to understand and prove its efficiency. It could have been interesting to show other use cases although the one picked was relevant.

In conclusion, an opening on future improvements could have proved useful for the interested reader.

-Table 1, a reminder of the initial hash size area for the traditional method could have been included to ease the reading
-A figure to illustrate method 2 would have been convenient

==+== E. Comments for PC

There is great value for future application in the now so-called Bloom filter, which will remain useful whatever the memory access scheme. This paper deserves to be accepted.

==-== Hidden from authors.

==+== Scratchpad (for unsaved private notes)

==+== End Review
